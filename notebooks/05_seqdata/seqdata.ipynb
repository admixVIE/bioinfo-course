{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db7ed003-3088-48d4-a113-26e69b94a6d3",
   "metadata": {},
   "source": [
    "# Brief recap\n",
    "\n",
    "File system & navigation: `cd `, `ls`, `less`, `cat` etc.; `cp` etc.\n",
    "\n",
    "Subsetting: `grep \"pattern\" file`, `cut -f1-2 -d \" \" file`, `awk 'pattern {subset}'` - complex subsetting\n",
    "\n",
    "Patterns, special characters, regular expressions: `==`, `&&`, `*`, `[abcd]`, `A|B` etc.\n",
    "\n",
    "**Anything unclear so far?**\n",
    "\n",
    "From now on, we stop working with the apples and oranges in the small text files in the subdirectories of this course. Instead, we should work on **real data** (big files) within the main home directory. These should be kept throughout the next sessions, as things build up. The notebooks may be updated inbetween, and any changes within the notebooks overwritten.\n",
    "\n",
    "In order to go there, do `cd ` without further input, and then let's go!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2baab7-7988-481e-9893-a10ed5d83de0",
   "metadata": {},
   "source": [
    "# Reference genomes & raw sequencing data \n",
    "\n",
    "We know what a reference genome is. The file format is called fasta, usually with the extension `.fa`, and plain text (or compressed with `.gz`).\n",
    "\n",
    "This file is nothing but a string of letters, representing a sequence (e.g. a genome of ~3.5 Gbp). Too big to download individually, hence we can use it in one directory.\n",
    "\n",
    "```\n",
    "less /home/local/ANTHROPOLOGY/kuhlwilmm83/refgen/hg19/hg19.p13.plusMT.no_alt_analysis_set.fa.gz\n",
    "```\n",
    "\n",
    "We should do some inspections here!\n",
    "\n",
    "*Now, let's get some data!* Fastq files contain the raw sequencing data. Here is a link with a samll example data set.\n",
    "\n",
    "```\n",
    "wget https://ucloud.univie.ac.at/index.php/s/BDxyMZaGyKedssT/download\n",
    "\n",
    "tar -zxvf download\n",
    "\n",
    "less test.fastq.gz\n",
    "```\n",
    "\n",
    "So, you see here:\n",
    "\n",
    "Header: read id, sequence info, read pair\n",
    "\n",
    "Sequence: ATGCGCGTATCGATGCTATGCâ€¦ bla bla\n",
    "\n",
    "Qualities: confidence for each base called (ASCII)\n",
    "\n",
    "**What do we do now?**\n",
    "\n",
    "* Count the number of reads, or lines in the fasta file. How do they relate?\n",
    "\n",
    "* Look at the start and end of the file.\n",
    "\n",
    "* Get the unique reads (hint: NR%4==2)\n",
    "\n",
    "* Search for patterns. E.g. \"CGTATGCCGTCTTCTGCTTG\" - what is going on? And why does it matter?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67fc21fc",
   "metadata": {},
   "source": [
    "# Adapter trimming\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "For trimming, we use a tool called `trimmomatic`, one of the possible tools for this taks. This is a tool implemented in a language called `java`, and we will not check how this looks like. On the good side, it is a command line tool, so you can used it the same way as you do with `grep` or other basic commands, providing parameters, and directions from where to take input and where to write output. These are some standard parameters (but of course, with new data, you may need to do adjustments):\n",
    "\n",
    "```\n",
    "java -jar /opt/trimmomatic.jar SE -phred33 test.fastq.gz \\\n",
    "test_p.fastq.gz \\\n",
    "ILLUMINACLIP:/home/local/ANTHROPOLOGY/kuhlwilmm83/refgen/adapters/TruSeq2-SE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36\n",
    "``` \n",
    "\n",
    "* Let's count the reads before and after this step!\n",
    "* What is the TruSeq2-SE.fa file?\n",
    "\n",
    "Now we have performed the first important step in raw data filtering, congrats!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b70785",
   "metadata": {},
   "source": [
    "# FASTQC\n",
    "\n",
    "Before moving on, let's have quick check on the raw data quality! In order to do that, we can use a program called FastQC. It is already installed on the cluster, and we can run it easily:\n",
    "\n",
    "``` \n",
    "mkdir fastqc-output\n",
    "/opt/FastQC/fastqc -o ./fastqc-output test.fastq.gz\n",
    "```\n",
    "\n",
    "This will create a report on data quality in `html` format, which we can inspect.\n",
    "\n",
    "Now we have made sure the data looks good.\n",
    "\n",
    "## Next time: mapping to the reference genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a78bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
